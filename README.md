# Text-Generation-Using-RNN
Give a large book from Project Gutenberg (e.g., The Count of Monte Cristo). Train a network to predict network trained to predict  the next textual character given a sequence of characters. Such network can be used to generate text by sampling a character given the first one.

This project uses TensorFlow and LSTM cells to train a rcurrent model able to generate sentences in plain English.

The same model can be used to learn from your exported Telegram conversations given a preprocessing function available in this repository.
